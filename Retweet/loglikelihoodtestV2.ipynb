{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24293938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données de test...\n",
      "Données chargées: (2000, 264)\n",
      "Données préparées\n",
      "\n",
      "Chargement du modèle Curriculum Learning...\n",
      "Calcul du log-likelihood pour Curriculum Learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Curriculum Learning: 100%|██████████| 200/200 [01:31<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RÉSULTATS LOG-LIKELIHOOD (Équation 8)\n",
      "============================================================\n",
      "Nombre de séquences de test: 2000\n",
      "Nombre total d'événements: 218465\n",
      "Log-likelihood total: -1417705.508148\n",
      "Log-likelihood moyen par séquence: -708.852754\n",
      "Log-likelihood par événement: -6.489394\n",
      "Écart-type: 351.058922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Imports et setup\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import h5py\n",
    "from LSTM_construction import CTLSTM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cellule 2: Charger les données de test\n",
    "print(\"Chargement des données de test...\")\n",
    "with h5py.File(\"RetweetTestData.h5\", \"r\") as fl:\n",
    "    EventsData = np.array(fl[\"EventsData\"])\n",
    "    timesData = np.array(fl[\"TimesData\"])\n",
    "    timeMaxData = np.array(fl[\"TimeMaxData\"])\n",
    "    SeqLengthData = np.array(fl[\"SeqLengthData\"])\n",
    "\n",
    "print(f\"Données chargées: {EventsData.shape}\")\n",
    "\n",
    "# Cellule 3: Préparation des données (même que vos notebooks existants)\n",
    "N_test = EventsData.shape[0]\n",
    "N_seq_Max = EventsData.shape[1]\n",
    "N_types = 3\n",
    "Events_one_hot = np.zeros((N_test, N_seq_Max, N_types))\n",
    "\n",
    "for seq in range(N_test):\n",
    "    for step in range(SeqLengthData[seq]):\n",
    "        ev = EventsData[seq, step]\n",
    "        if ev >= 0:\n",
    "            Events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "# Conversion en tenseurs\n",
    "timeScale = 1.0\n",
    "EvTens = pt.tensor(Events_one_hot).double()\n",
    "EvIndTens = pt.tensor(EventsData).long()\n",
    "timeTensor = pt.tensor(timesData/timeScale).double()\n",
    "tMaxTensor = pt.tensor(timeMaxData/timeScale).double()\n",
    "mask = EvIndTens.ge(-1+0.001)\n",
    "\n",
    "print(\"Données préparées\")\n",
    "\n",
    "def evaluate_model(model_path, model_name):\n",
    "    \"\"\"\n",
    "    Évalue un modèle et retourne les log-likelihoods par séquence\n",
    "    \"\"\"\n",
    "    print(f\"\\nChargement du modèle {model_name}...\")\n",
    "    net = pt.load(model_path, weights_only=False)\n",
    "    net.eval()\n",
    "    \n",
    "    BatchSize = 10\n",
    "    sequence_log_likelihoods = []\n",
    "    \n",
    "    print(f\"Calcul du log-likelihood pour {model_name}...\")\n",
    "    \n",
    "    with pt.no_grad():\n",
    "        for batchInd in tqdm(range(0, N_test, BatchSize), desc=f\"Evaluating {model_name}\"):\n",
    "            batch_end = min(batchInd + BatchSize, N_test)\n",
    "            BatchEventsHot = EvTens[batchInd:batch_end]\n",
    "            BatchEventsInd = EvIndTens[batchInd:batch_end]\n",
    "            BatchTimes = timeTensor[batchInd:batch_end]\n",
    "            BatchTMax = tMaxTensor[batchInd:batch_end]\n",
    "            BatchMask = mask[batchInd:batch_end]\n",
    "            \n",
    "            # Forward pass\n",
    "            lambOuts, CLows, Cbars, deltas, OutGates = net.forward(\n",
    "                BatchEventsHot, BatchMask, BatchTimes\n",
    "            )\n",
    "            \n",
    "            # Utiliser les fonctions modifiées qui retournent les losses individuelles\n",
    "            LMC, _, _, individual_mc_losses = net.MC_Loss(\n",
    "                BatchTimes, BatchTMax, CLows, Cbars, deltas, OutGates, Nsamples=1000\n",
    "            )\n",
    "            \n",
    "            LogLikeLoss, individual_log_losses = net.logLoss(BatchEventsInd, BatchMask, lambOuts)\n",
    "            \n",
    "            # Log-likelihood = -individual_log_losses - individual_mc_losses\n",
    "            # (car logLoss retourne déjà le négatif et MC_Loss l'intégrale positive)\n",
    "            for i in range(len(individual_log_losses)):\n",
    "                ll = -individual_log_losses[i] - individual_mc_losses[i]\n",
    "\n",
    "                \n",
    "                sequence_log_likelihoods.append(ll)\n",
    "    \n",
    "    return np.array(sequence_log_likelihoods)\n",
    "\n",
    "# Cellule 4: Évaluation des deux modèles\n",
    "curriculum_ll = evaluate_model(\"Comparison_ModelsV6/Curriculum_LearningV2_finalV6.pt\", \"Curriculum Learning\")\n",
    "total_events = np.sum(SeqLengthData)\n",
    "total_curriculum_ll = np.sum(curriculum_ll)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RÉSULTATS LOG-LIKELIHOOD (Équation 8)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre de séquences de test: {N_test}\")\n",
    "print(f\"Nombre total d'événements: {total_events}\")\n",
    "print(f\"Log-likelihood total: {total_curriculum_ll:.6f}\")\n",
    "print(f\"Log-likelihood moyen par séquence: {np.mean(curriculum_ll):.6f}\")\n",
    "print(f\"Log-likelihood par événement: {total_curriculum_ll / total_events:.6f}\")\n",
    "print(f\"Écart-type: {np.std(curriculum_ll):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5562ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données de test...\n",
      "Données chargées: (2000, 264)\n",
      "Données préparées\n",
      "\n",
      "Chargement du modèle old Curriculum Learning...\n",
      "Calcul du log-likelihood pour old Curriculum Learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating old Curriculum Learning: 100%|██████████| 200/200 [02:25<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RÉSULTATS LOG-LIKELIHOOD (Équation 8)\n",
      "============================================================\n",
      "Nombre de séquences de test: 2000\n",
      "Nombre total d'événements: 218465\n",
      "Log-likelihood total: -1433822.646585\n",
      "Log-likelihood moyen par séquence: -716.911323\n",
      "Log-likelihood par événement: -6.563169\n",
      "Écart-type: 353.659646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Imports et setup\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import h5py\n",
    "from LSTM_construction import CTLSTM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cellule 2: Charger les données de test\n",
    "print(\"Chargement des données de test...\")\n",
    "with h5py.File(\"RetweetTestData.h5\", \"r\") as fl:\n",
    "    EventsData = np.array(fl[\"EventsData\"])\n",
    "    timesData = np.array(fl[\"TimesData\"])\n",
    "    timeMaxData = np.array(fl[\"TimeMaxData\"])\n",
    "    SeqLengthData = np.array(fl[\"SeqLengthData\"])\n",
    "\n",
    "print(f\"Données chargées: {EventsData.shape}\")\n",
    "\n",
    "# Cellule 3: Préparation des données (même que vos notebooks existants)\n",
    "N_test = EventsData.shape[0]\n",
    "N_seq_Max = EventsData.shape[1]\n",
    "N_types = 3\n",
    "Events_one_hot = np.zeros((N_test, N_seq_Max, N_types))\n",
    "\n",
    "for seq in range(N_test):\n",
    "    for step in range(SeqLengthData[seq]):\n",
    "        ev = EventsData[seq, step]\n",
    "        if ev >= 0:\n",
    "            Events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "# Conversion en tenseurs\n",
    "timeScale = 1.0\n",
    "EvTens = pt.tensor(Events_one_hot).double()\n",
    "EvIndTens = pt.tensor(EventsData).long()\n",
    "timeTensor = pt.tensor(timesData/timeScale).double()\n",
    "tMaxTensor = pt.tensor(timeMaxData/timeScale).double()\n",
    "mask = EvIndTens.ge(-1+0.001)\n",
    "\n",
    "print(\"Données préparées\")\n",
    "\n",
    "def evaluate_model(model_path, model_name):\n",
    "    \"\"\"\n",
    "    Évalue un modèle et retourne les log-likelihoods par séquence\n",
    "    \"\"\"\n",
    "    print(f\"\\nChargement du modèle {model_name}...\")\n",
    "    net = pt.load(model_path, weights_only=False)\n",
    "    net.eval()\n",
    "    \n",
    "    BatchSize = 10\n",
    "    sequence_log_likelihoods = []\n",
    "    \n",
    "    print(f\"Calcul du log-likelihood pour {model_name}...\")\n",
    "    \n",
    "    with pt.no_grad():\n",
    "        for batchInd in tqdm(range(0, N_test, BatchSize), desc=f\"Evaluating {model_name}\"):\n",
    "            batch_end = min(batchInd + BatchSize, N_test)\n",
    "            BatchEventsHot = EvTens[batchInd:batch_end]\n",
    "            BatchEventsInd = EvIndTens[batchInd:batch_end]\n",
    "            BatchTimes = timeTensor[batchInd:batch_end]\n",
    "            BatchTMax = tMaxTensor[batchInd:batch_end]\n",
    "            BatchMask = mask[batchInd:batch_end]\n",
    "            \n",
    "            # Forward pass\n",
    "            lambOuts, CLows, Cbars, deltas, OutGates = net.forward(\n",
    "                BatchEventsHot, BatchMask, BatchTimes\n",
    "            )\n",
    "            \n",
    "            # Utiliser les fonctions modifiées qui retournent les losses individuelles\n",
    "            LMC, _, _, individual_mc_losses = net.MC_Loss(\n",
    "                BatchTimes, BatchTMax, CLows, Cbars, deltas, OutGates, Nsamples=1000\n",
    "            )\n",
    "            \n",
    "            LogLikeLoss, individual_log_losses = net.logLoss(BatchEventsInd, BatchMask, lambOuts)\n",
    "            \n",
    "            # Log-likelihood = -individual_log_losses - individual_mc_losses\n",
    "            # (car logLoss retourne déjà le négatif et MC_Loss l'intégrale positive)\n",
    "            for i in range(len(individual_log_losses)):\n",
    "                ll = -individual_log_losses[i] - individual_mc_losses[i]\n",
    "\n",
    "                \n",
    "                sequence_log_likelihoods.append(ll)\n",
    "    \n",
    "    return np.array(sequence_log_likelihoods)\n",
    "\n",
    "# Cellule 4: Évaluation des deux modèles\n",
    "curriculum_ll = evaluate_model(\"Comparison_ModelsV6/Curriculum_Learning_finalV6.pt\", \"old Curriculum Learning\")\n",
    "total_events = np.sum(SeqLengthData)\n",
    "total_curriculum_ll = np.sum(curriculum_ll)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RÉSULTATS LOG-LIKELIHOOD (Équation 8)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre de séquences de test: {N_test}\")\n",
    "print(f\"Nombre total d'événements: {total_events}\")\n",
    "print(f\"Log-likelihood total: {total_curriculum_ll:.6f}\")\n",
    "print(f\"Log-likelihood moyen par séquence: {np.mean(curriculum_ll):.6f}\")\n",
    "print(f\"Log-likelihood par événement: {total_curriculum_ll / total_events:.6f}\")\n",
    "print(f\"Écart-type: {np.std(curriculum_ll):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99522fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données de test...\n",
      "Données chargées: (2000, 264)\n",
      "Données préparées\n",
      "\n",
      "Chargement du modèle Progressive Random...\n",
      "Calcul du log-likelihood pour Progressive Random...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Progressive Random: 100%|██████████| 200/200 [01:31<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RÉSULTATS LOG-LIKELIHOOD (Équation 8)\n",
      "============================================================\n",
      "Nombre de séquences de test: 2000\n",
      "Nombre total d'événements: 218465\n",
      "Log-likelihood total: -1458475.576305\n",
      "Log-likelihood moyen par séquence: -729.237788\n",
      "Log-likelihood par événement: -6.676015\n",
      "Écart-type: 356.437498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Imports et setup\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import h5py\n",
    "from LSTM_construction import CTLSTM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cellule 2: Charger les données de test\n",
    "print(\"Chargement des données de test...\")\n",
    "with h5py.File(\"RetweetTestData.h5\", \"r\") as fl:\n",
    "    EventsData = np.array(fl[\"EventsData\"])\n",
    "    timesData = np.array(fl[\"TimesData\"])\n",
    "    timeMaxData = np.array(fl[\"TimeMaxData\"])\n",
    "    SeqLengthData = np.array(fl[\"SeqLengthData\"])\n",
    "\n",
    "print(f\"Données chargées: {EventsData.shape}\")\n",
    "\n",
    "# Cellule 3: Préparation des données (même que vos notebooks existants)\n",
    "N_test = EventsData.shape[0]\n",
    "N_seq_Max = EventsData.shape[1]\n",
    "N_types = 3\n",
    "Events_one_hot = np.zeros((N_test, N_seq_Max, N_types))\n",
    "\n",
    "for seq in range(N_test):\n",
    "    for step in range(SeqLengthData[seq]):\n",
    "        ev = EventsData[seq, step]\n",
    "        if ev >= 0:\n",
    "            Events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "# Conversion en tenseurs\n",
    "timeScale = 1.0\n",
    "EvTens = pt.tensor(Events_one_hot).double()\n",
    "EvIndTens = pt.tensor(EventsData).long()\n",
    "timeTensor = pt.tensor(timesData/timeScale).double()\n",
    "tMaxTensor = pt.tensor(timeMaxData/timeScale).double()\n",
    "mask = EvIndTens.ge(-1+0.001)\n",
    "\n",
    "print(\"Données préparées\")\n",
    "\n",
    "def evaluate_model(model_path, model_name):\n",
    "    \"\"\"\n",
    "    Évalue un modèle et retourne les log-likelihoods par séquence\n",
    "    \"\"\"\n",
    "    print(f\"\\nChargement du modèle {model_name}...\")\n",
    "    net = pt.load(model_path, weights_only=False)\n",
    "    net.eval()\n",
    "    \n",
    "    BatchSize = 10\n",
    "    sequence_log_likelihoods = []\n",
    "    \n",
    "    print(f\"Calcul du log-likelihood pour {model_name}...\")\n",
    "    \n",
    "    with pt.no_grad():\n",
    "        for batchInd in tqdm(range(0, N_test, BatchSize), desc=f\"Evaluating {model_name}\"):\n",
    "            batch_end = min(batchInd + BatchSize, N_test)\n",
    "            BatchEventsHot = EvTens[batchInd:batch_end]\n",
    "            BatchEventsInd = EvIndTens[batchInd:batch_end]\n",
    "            BatchTimes = timeTensor[batchInd:batch_end]\n",
    "            BatchTMax = tMaxTensor[batchInd:batch_end]\n",
    "            BatchMask = mask[batchInd:batch_end]\n",
    "            \n",
    "            # Forward pass\n",
    "            lambOuts, CLows, Cbars, deltas, OutGates = net.forward(\n",
    "                BatchEventsHot, BatchMask, BatchTimes\n",
    "            )\n",
    "            \n",
    "            # Utiliser les fonctions modifiées qui retournent les losses individuelles\n",
    "            LMC, _, _, individual_mc_losses = net.MC_Loss(\n",
    "                BatchTimes, BatchTMax, CLows, Cbars, deltas, OutGates, Nsamples=1000\n",
    "            )\n",
    "            \n",
    "            LogLikeLoss, individual_log_losses = net.logLoss(BatchEventsInd, BatchMask, lambOuts)\n",
    "            \n",
    "            # Log-likelihood = -individual_log_losses - individual_mc_losses\n",
    "            # (car logLoss retourne déjà le négatif et MC_Loss l'intégrale positive)\n",
    "            for i in range(len(individual_log_losses)):\n",
    "                ll = -individual_log_losses[i] - individual_mc_losses[i]\n",
    "\n",
    "                \n",
    "                sequence_log_likelihoods.append(ll)\n",
    "    \n",
    "    return np.array(sequence_log_likelihoods)\n",
    "\n",
    "# Cellule 4: Évaluation des deux modèles\n",
    "curriculum_ll = evaluate_model(\"Comparison_ModelsV6/Progressive_Random_finalV6.pt\", \"Progressive Random\")\n",
    "total_events = np.sum(SeqLengthData)\n",
    "total_curriculum_ll = np.sum(curriculum_ll)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RÉSULTATS LOG-LIKELIHOOD (Équation 8)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre de séquences de test: {N_test}\")\n",
    "print(f\"Nombre total d'événements: {total_events}\")\n",
    "print(f\"Log-likelihood total: {total_curriculum_ll:.6f}\")\n",
    "print(f\"Log-likelihood moyen par séquence: {np.mean(curriculum_ll):.6f}\")\n",
    "print(f\"Log-likelihood par événement: {total_curriculum_ll / total_events:.6f}\")\n",
    "print(f\"Écart-type: {np.std(curriculum_ll):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f16e23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données de test...\n",
      "Données chargées: (2000, 264)\n",
      "Données préparées\n",
      "\n",
      "Chargement du modèle Random Buckets...\n",
      "Calcul du log-likelihood pour Random Buckets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Random Buckets: 100%|██████████| 200/200 [01:36<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RÉSULTATS LOG-LIKELIHOOD (Équation 8)\n",
      "============================================================\n",
      "Nombre de séquences de test: 2000\n",
      "Nombre total d'événements: 218465\n",
      "Log-likelihood total: -1454729.476498\n",
      "Log-likelihood moyen par séquence: -727.364738\n",
      "Log-likelihood par événement: -6.658867\n",
      "Écart-type: 355.746568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Imports et setup\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import h5py\n",
    "from LSTM_construction import CTLSTM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cellule 2: Charger les données de test\n",
    "print(\"Chargement des données de test...\")\n",
    "with h5py.File(\"RetweetTestData.h5\", \"r\") as fl:\n",
    "    EventsData = np.array(fl[\"EventsData\"])\n",
    "    timesData = np.array(fl[\"TimesData\"])\n",
    "    timeMaxData = np.array(fl[\"TimeMaxData\"])\n",
    "    SeqLengthData = np.array(fl[\"SeqLengthData\"])\n",
    "\n",
    "print(f\"Données chargées: {EventsData.shape}\")\n",
    "\n",
    "# Cellule 3: Préparation des données (même que vos notebooks existants)\n",
    "N_test = EventsData.shape[0]\n",
    "N_seq_Max = EventsData.shape[1]\n",
    "N_types = 3\n",
    "Events_one_hot = np.zeros((N_test, N_seq_Max, N_types))\n",
    "\n",
    "for seq in range(N_test):\n",
    "    for step in range(SeqLengthData[seq]):\n",
    "        ev = EventsData[seq, step]\n",
    "        if ev >= 0:\n",
    "            Events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "# Conversion en tenseurs\n",
    "timeScale = 1.0\n",
    "EvTens = pt.tensor(Events_one_hot).double()\n",
    "EvIndTens = pt.tensor(EventsData).long()\n",
    "timeTensor = pt.tensor(timesData/timeScale).double()\n",
    "tMaxTensor = pt.tensor(timeMaxData/timeScale).double()\n",
    "mask = EvIndTens.ge(-1+0.001)\n",
    "\n",
    "print(\"Données préparées\")\n",
    "\n",
    "def evaluate_model(model_path, model_name):\n",
    "    \"\"\"\n",
    "    Évalue un modèle et retourne les log-likelihoods par séquence\n",
    "    \"\"\"\n",
    "    print(f\"\\nChargement du modèle {model_name}...\")\n",
    "    net = pt.load(model_path, weights_only=False)\n",
    "    net.eval()\n",
    "    \n",
    "    BatchSize = 10\n",
    "    sequence_log_likelihoods = []\n",
    "    \n",
    "    print(f\"Calcul du log-likelihood pour {model_name}...\")\n",
    "    \n",
    "    with pt.no_grad():\n",
    "        for batchInd in tqdm(range(0, N_test, BatchSize), desc=f\"Evaluating {model_name}\"):\n",
    "            batch_end = min(batchInd + BatchSize, N_test)\n",
    "            BatchEventsHot = EvTens[batchInd:batch_end]\n",
    "            BatchEventsInd = EvIndTens[batchInd:batch_end]\n",
    "            BatchTimes = timeTensor[batchInd:batch_end]\n",
    "            BatchTMax = tMaxTensor[batchInd:batch_end]\n",
    "            BatchMask = mask[batchInd:batch_end]\n",
    "            \n",
    "            # Forward pass\n",
    "            lambOuts, CLows, Cbars, deltas, OutGates = net.forward(\n",
    "                BatchEventsHot, BatchMask, BatchTimes\n",
    "            )\n",
    "            \n",
    "            # Utiliser les fonctions modifiées qui retournent les losses individuelles\n",
    "            LMC, _, _, individual_mc_losses = net.MC_Loss(\n",
    "                BatchTimes, BatchTMax, CLows, Cbars, deltas, OutGates, Nsamples=1000\n",
    "            )\n",
    "            \n",
    "            LogLikeLoss, individual_log_losses = net.logLoss(BatchEventsInd, BatchMask, lambOuts)\n",
    "            \n",
    "            # Log-likelihood = -individual_log_losses - individual_mc_losses\n",
    "            # (car logLoss retourne déjà le négatif et MC_Loss l'intégrale positive)\n",
    "            for i in range(len(individual_log_losses)):\n",
    "                ll = -individual_log_losses[i] - individual_mc_losses[i]\n",
    "\n",
    "                \n",
    "                sequence_log_likelihoods.append(ll)\n",
    "    \n",
    "    return np.array(sequence_log_likelihoods)\n",
    "\n",
    "# Cellule 4: Évaluation des deux modèles\n",
    "curriculum_ll = evaluate_model(\"Comparison_ModelsV6/Random_Buckets_finalV6.pt\", \"Random Buckets\")\n",
    "total_events = np.sum(SeqLengthData)\n",
    "total_curriculum_ll = np.sum(curriculum_ll)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RÉSULTATS LOG-LIKELIHOOD (Équation 8)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre de séquences de test: {N_test}\")\n",
    "print(f\"Nombre total d'événements: {total_events}\")\n",
    "print(f\"Log-likelihood total: {total_curriculum_ll:.6f}\")\n",
    "print(f\"Log-likelihood moyen par séquence: {np.mean(curriculum_ll):.6f}\")\n",
    "print(f\"Log-likelihood par événement: {total_curriculum_ll / total_events:.6f}\")\n",
    "print(f\"Écart-type: {np.std(curriculum_ll):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61577529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données de test...\n",
      "Données chargées: (2000, 264)\n",
      "Données préparées\n",
      "\n",
      "Chargement du modèle original model...\n",
      "Calcul du log-likelihood pour original model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating original model: 100%|██████████| 200/200 [01:25<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RÉSULTATS LOG-LIKELIHOOD (Équation 8)\n",
      "============================================================\n",
      "Nombre de séquences de test: 2000\n",
      "Nombre total d'événements: 218465\n",
      "Log-likelihood total: -1461968.750108\n",
      "Log-likelihood moyen par séquence: -730.984375\n",
      "Log-likelihood par événement: -6.692004\n",
      "Écart-type: 357.604332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Imports et setup\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import h5py\n",
    "from LSTM_construction import CTLSTM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cellule 2: Charger les données de test\n",
    "print(\"Chargement des données de test...\")\n",
    "with h5py.File(\"RetweetTestData.h5\", \"r\") as fl:\n",
    "    EventsData = np.array(fl[\"EventsData\"])\n",
    "    timesData = np.array(fl[\"TimesData\"])\n",
    "    timeMaxData = np.array(fl[\"TimeMaxData\"])\n",
    "    SeqLengthData = np.array(fl[\"SeqLengthData\"])\n",
    "\n",
    "print(f\"Données chargées: {EventsData.shape}\")\n",
    "\n",
    "# Cellule 3: Préparation des données (même que vos notebooks existants)\n",
    "N_test = EventsData.shape[0]\n",
    "N_seq_Max = EventsData.shape[1]\n",
    "N_types = 3\n",
    "Events_one_hot = np.zeros((N_test, N_seq_Max, N_types))\n",
    "\n",
    "for seq in range(N_test):\n",
    "    for step in range(SeqLengthData[seq]):\n",
    "        ev = EventsData[seq, step]\n",
    "        if ev >= 0:\n",
    "            Events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "# Conversion en tenseurs\n",
    "timeScale = 1.0\n",
    "EvTens = pt.tensor(Events_one_hot).double()\n",
    "EvIndTens = pt.tensor(EventsData).long()\n",
    "timeTensor = pt.tensor(timesData/timeScale).double()\n",
    "tMaxTensor = pt.tensor(timeMaxData/timeScale).double()\n",
    "mask = EvIndTens.ge(-1+0.001)\n",
    "\n",
    "print(\"Données préparées\")\n",
    "\n",
    "def evaluate_model(model_path, model_name):\n",
    "    \"\"\"\n",
    "    Évalue un modèle et retourne les log-likelihoods par séquence\n",
    "    \"\"\"\n",
    "    print(f\"\\nChargement du modèle {model_name}...\")\n",
    "    net = pt.load(model_path, weights_only=False)\n",
    "    net.eval()\n",
    "    \n",
    "    BatchSize = 10\n",
    "    sequence_log_likelihoods = []\n",
    "    \n",
    "    print(f\"Calcul du log-likelihood pour {model_name}...\")\n",
    "    \n",
    "    with pt.no_grad():\n",
    "        for batchInd in tqdm(range(0, N_test, BatchSize), desc=f\"Evaluating {model_name}\"):\n",
    "            batch_end = min(batchInd + BatchSize, N_test)\n",
    "            BatchEventsHot = EvTens[batchInd:batch_end]\n",
    "            BatchEventsInd = EvIndTens[batchInd:batch_end]\n",
    "            BatchTimes = timeTensor[batchInd:batch_end]\n",
    "            BatchTMax = tMaxTensor[batchInd:batch_end]\n",
    "            BatchMask = mask[batchInd:batch_end]\n",
    "            \n",
    "            # Forward pass\n",
    "            lambOuts, CLows, Cbars, deltas, OutGates = net.forward(\n",
    "                BatchEventsHot, BatchMask, BatchTimes\n",
    "            )\n",
    "            \n",
    "            # Utiliser les fonctions modifiées qui retournent les losses individuelles\n",
    "            LMC, _, _, individual_mc_losses = net.MC_Loss(\n",
    "                BatchTimes, BatchTMax, CLows, Cbars, deltas, OutGates, Nsamples=1000\n",
    "            )\n",
    "            \n",
    "            LogLikeLoss, individual_log_losses = net.logLoss(BatchEventsInd, BatchMask, lambOuts)\n",
    "            \n",
    "            # Log-likelihood = -individual_log_losses - individual_mc_losses\n",
    "            # (car logLoss retourne déjà le négatif et MC_Loss l'intégrale positive)\n",
    "            for i in range(len(individual_log_losses)):\n",
    "                ll = -individual_log_losses[i] - individual_mc_losses[i]\n",
    "\n",
    "                \n",
    "                sequence_log_likelihoods.append(ll)\n",
    "    \n",
    "    return np.array(sequence_log_likelihoods)\n",
    "\n",
    "# Cellule 4: Évaluation des deux modèles\n",
    "curriculum_ll = evaluate_model(\"RetweetNetsV3/TrainNet_ep11V2.pt\", \"original model\")\n",
    "total_events = np.sum(SeqLengthData)\n",
    "total_curriculum_ll = np.sum(curriculum_ll)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RÉSULTATS LOG-LIKELIHOOD (Équation 8)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre de séquences de test: {N_test}\")\n",
    "print(f\"Nombre total d'événements: {total_events}\")\n",
    "print(f\"Log-likelihood total: {total_curriculum_ll:.6f}\")\n",
    "print(f\"Log-likelihood moyen par séquence: {np.mean(curriculum_ll):.6f}\")\n",
    "print(f\"Log-likelihood par événement: {total_curriculum_ll / total_events:.6f}\")\n",
    "print(f\"Écart-type: {np.std(curriculum_ll):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aca725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données de test...\n",
      "Données chargées: (2000, 264)\n",
      "Données préparées\n",
      "\n",
      "Chargement du modèle original model...\n",
      "Calcul du log-likelihood pour original model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating original model: 100%|██████████| 200/200 [04:06<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RÉSULTATS LOG-LIKELIHOOD (Équation 8)\n",
      "============================================================\n",
      "Nombre de séquences de test: 2000\n",
      "Nombre total d'événements: 218465\n",
      "Log-likelihood total: -1226442.881224\n",
      "Log-likelihood moyen par séquence: -613.221441\n",
      "Log-likelihood par événement: -5.613910\n",
      "Écart-type: 307.986081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Imports et setup\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import h5py\n",
    "from LSTM_construction import CTLSTM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cellule 2: Charger les données de test\n",
    "print(\"Chargement des données de test...\")\n",
    "with h5py.File(\"RetweetTestData.h5\", \"r\") as fl:\n",
    "    EventsData = np.array(fl[\"EventsData\"])\n",
    "    timesData = np.array(fl[\"TimesData\"])\n",
    "    timeMaxData = np.array(fl[\"TimeMaxData\"])\n",
    "    SeqLengthData = np.array(fl[\"SeqLengthData\"])\n",
    "\n",
    "print(f\"Données chargées: {EventsData.shape}\")\n",
    "\n",
    "# Cellule 3: Préparation des données (même que vos notebooks existants)\n",
    "N_test = EventsData.shape[0]\n",
    "N_seq_Max = EventsData.shape[1]\n",
    "N_types = 3\n",
    "Events_one_hot = np.zeros((N_test, N_seq_Max, N_types))\n",
    "\n",
    "for seq in range(N_test):\n",
    "    for step in range(SeqLengthData[seq]):\n",
    "        ev = EventsData[seq, step]\n",
    "        if ev >= 0:\n",
    "            Events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "# Conversion en tenseurs\n",
    "timeScale = 1.0\n",
    "EvTens = pt.tensor(Events_one_hot).double()\n",
    "EvIndTens = pt.tensor(EventsData).long()\n",
    "timeTensor = pt.tensor(timesData/timeScale).double()\n",
    "tMaxTensor = pt.tensor(timeMaxData/timeScale).double()\n",
    "mask = EvIndTens.ge(-1+0.001)\n",
    "\n",
    "print(\"Données préparées\")\n",
    "\n",
    "def evaluate_model(model_path, model_name):\n",
    "    \"\"\"\n",
    "    Évalue un modèle et retourne les log-likelihoods par séquence\n",
    "    \"\"\"\n",
    "    print(f\"\\nChargement du modèle {model_name}...\")\n",
    "    net = pt.load(model_path, weights_only=False)\n",
    "    net.eval()\n",
    "    \n",
    "    BatchSize = 10\n",
    "    sequence_log_likelihoods = []\n",
    "    \n",
    "    print(f\"Calcul du log-likelihood pour {model_name}...\")\n",
    "    \n",
    "    with pt.no_grad():\n",
    "        for batchInd in tqdm(range(0, N_test, BatchSize), desc=f\"Evaluating {model_name}\"):\n",
    "            batch_end = min(batchInd + BatchSize, N_test)\n",
    "            BatchEventsHot = EvTens[batchInd:batch_end]\n",
    "            BatchEventsInd = EvIndTens[batchInd:batch_end]\n",
    "            BatchTimes = timeTensor[batchInd:batch_end]\n",
    "            BatchTMax = tMaxTensor[batchInd:batch_end]\n",
    "            BatchMask = mask[batchInd:batch_end]\n",
    "            \n",
    "            # Forward pass\n",
    "            lambOuts, CLows, Cbars, deltas, OutGates = net.forward(\n",
    "                BatchEventsHot, BatchMask, BatchTimes\n",
    "            )\n",
    "            \n",
    "            # Utiliser les fonctions modifiées qui retournent les losses individuelles\n",
    "            LMC, _, _, individual_mc_losses = net.MC_Loss(\n",
    "                BatchTimes, BatchTMax, CLows, Cbars, deltas, OutGates, Nsamples=1000\n",
    "            )\n",
    "            \n",
    "            LogLikeLoss, individual_log_losses = net.logLoss(BatchEventsInd, BatchMask, lambOuts)\n",
    "            \n",
    "            # Log-likelihood = -individual_log_losses - individual_mc_losses\n",
    "            # (car logLoss retourne déjà le négatif et MC_Loss l'intégrale positive)\n",
    "            for i in range(len(individual_log_losses)):\n",
    "                ll = -individual_log_losses[i] - individual_mc_losses[i]\n",
    "\n",
    "                \n",
    "                sequence_log_likelihoods.append(ll)\n",
    "    \n",
    "    return np.array(sequence_log_likelihoods)\n",
    "\n",
    "# Cellule 4: Évaluation des deux modèles\n",
    "curriculum_ll = evaluate_model(\"RetweetNetsV9/TrainNet_ep19V2.pt\", \"original model\")\n",
    "total_events = np.sum(SeqLengthData)\n",
    "total_curriculum_ll = np.sum(curriculum_ll)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RÉSULTATS LOG-LIKELIHOOD (Équation 8)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre de séquences de test: {N_test}\")\n",
    "print(f\"Nombre total d'événements: {total_events}\")\n",
    "print(f\"Log-likelihood total: {total_curriculum_ll:.6f}\")\n",
    "print(f\"Log-likelihood moyen par séquence: {np.mean(curriculum_ll):.6f}\")\n",
    "print(f\"Log-likelihood par événement: {total_curriculum_ll / total_events:.6f}\")\n",
    "print(f\"Écart-type: {np.std(curriculum_ll):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dab39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
